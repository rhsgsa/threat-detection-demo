version: "3.5"

services:

  mock-image-acquirer:
    container_name: mock-image-acquirer
    image: "docker.io/library/eclipse-mosquitto:2.0.18-openssl"
    entrypoint:
    - sh
    - "-c"
    - |
      while true; do
        while read -r line; do
          echo "$$line"
          sleep 15
        done < /mocks/mqtt.txt
      done | mosquitto_pub -h mqtt -t alerts -l
    volumes:
    - ../../mocks/mqtt.txt:/mocks/mqtt.txt:ro,z
    depends_on:
    - mqtt

  mqtt:
    container_name: mqtt
    image: "docker.io/library/eclipse-mosquitto:2.0.18-openssl"
    ports:
    - 1883:1883
    volumes:
    - ../../mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf:ro,z

  build_react:
    container_name: build-react
    image: "node:16"
    working_dir: /app
    entrypoint:
    - bash
    - "-c"
    - |
      echo "copying react files to /app..."
      tar -C /host -cf - . | tar -xvf -
      echo "installing dependencies..."
      npm install
      echo "generating static files..."
      npm run build
      echo "copying static files to /static..."
      tar -C build -cf - . | tar -C /static -xvf -
    volumes:
    - react:/static
    - ../../frontend/react:/host

  frontend:
    container_name: frontend
    image: "quay.io/rhsgsa/threat-frontend:1.92"
    environment:
    - MQTTBROKER=tcp://mqtt:1883
    - PORT=8080
    - CORS=*
    #- DOCROOT=
    - ALERTSTOPIC=alerts
    - OLLAMAURL=http://mock-ollama:11434/api/generate
    - OPENAIURL=http://mock-openai:8012/v1
    - OPENAIPROMPT=You are tailored to provide concise threat assessments. Reply with the level of threat, either low, medium or high. Explanations for assessments are not provided, maintaining a focus on clear, concise classification without additional commentary.
    - PROMPTS=/mocks/prompts.txt
    ports:
    - 8080:8080
    volumes:
    - react:/var/www/html
    - ../../mocks/prompts.txt:/mocks/prompts.txt:ro,z
    depends_on:
    - mqtt
    - build_react

  mock-ollama:
    container_name: mock-ollama
    image: "ghcr.io/kwkoo/mock-llm"
    environment:
    - PORT=11434
    - SOURCE=/mocks/ollama.txt
    - LINESLEEPMSECS=50
    ports:
    - 11434:11434
    volumes:
    - ../../mocks/ollama.txt:/mocks/ollama.txt:ro,z

  mock-openai:
    container_name: mock-openai
    image: "ghcr.io/kwkoo/mock-llm"
    environment:
    - PORT=8012
    - SOURCE=/mocks/openai.txt
    - LINESLEEPMSECS=50
    - 'RESPONSEPREFIX=data: '
    - RESPONSESTOP="finish_reason":"stop"
    ports:
    - 8012:8012
    volumes:
    - ../../mocks/openai.txt:/mocks/openai.txt:ro,z

volumes:
  react:
